# This script extracts the amount of reads from fastq files and sam files generated by bwa-mem2, as well as the amount of reads that were classified by kraken2.
# Make sure you are in an evironment with fastp and samtools installed.

import csv
import os
import re
import argparse

# Create the parser
parser = argparse.ArgumentParser(description='Extract read counts from sam files and kraken reports.')

# Add the arguments
parser.add_argument('--samplesheet', type=str, required=True, help='Path to CSV file containing sample information')
parser.add_argument('--output_file', type=str, required=True, help='Path to output file')
parser.add_argument('--previous_output_dir', type=str, required=True, help='Path to directory with previous outputs from kraken2')

# Parse the arguments
args = parser.parse_args()

# Assign the arguments to variables
samplesheet = args.samplesheet
output_file = args.output_file
previous_output_dir = args.previous_output_dir

def extract_homo_sapiens_reads(sample):
    filename = f"{previous_output_dir}kraken2/reports/{sample}_kraken2_report.txt"
    #"/mnt/FS2/data_1/PRJNA866654_Lung_Cancer_Gut_Microbiome/Results/kraken_only/kraken2/reports/SRR20881974_kraken2_report.txt"
    homo_number = 0
    bac_number = 0
    with open(filename, 'r') as file:
        for line in file:
            columns = line.split('\t')
            if 'Homo sapiens' in columns[5]:
                homo_number = int(columns[1])
                print(f"Number of Homo sapiens reads for sample {sample}: {homo_number}", flush=True)
            if re.fullmatch('^2$', columns[4]):
                bac_number = int(columns[1])
                print(f"Number of Bacterial reads for sample {sample}: {bac_number}", flush=True)
    return homo_number, bac_number

# Initialize a counter for the number of samples processed
num_samples_processed = 0

# Create output file if it does not exist
if not os.path.exists(output_file):
    with open(output_file, 'w', newline='') as outfile:
        # Create headers
        #headers = ['sample', 'total_input_reads', 'human_bwa', 'not_human_bwa', 'human_kraken', 'bacterial_kraken']
        headers = ['sample', 'human_kraken_only', 'bacterial_kraken_only']
        # Write headers to the output file
        out_writer = csv.writer(outfile)
        out_writer.writerow(headers)
        # Read sample information from the CSV file and run tools for each sample
        with open(samplesheet, "r") as ssheet:
            ssheet_reader = csv.DictReader(ssheet)
            for row in ssheet_reader:
                sample = row["sample"]
                # Run flagstat for the current sample
                # total_input, properly_paired, unconcordantly_aligned = flagstat(sample)
                # extract homo sapiens reads
                homo_number, bac_number = extract_homo_sapiens_reads(sample)
                # Write values from each sample to csv
                out_writer.writerow([sample, homo_number, bac_number])
                # Increment the counter
                num_samples_processed += 1
# Exit if file exists, print error
else:
    print(f"Error: Output file '{output_file}' already exists.")
    exit(1)

print(f"Processed all {num_samples_processed} samples", flush=True)
